# CausalIE on Education Papers

Visualizer for education papers: http://papers-ai.vercel.app

## Part 1: Codes for IE

- Extract entities (by Flavio)
- Extract entities (by Eleanor)
- Extract relations (by Eleanor)
- Visualization (by Flavio)

## Part 2: Codes for Causal Discovery

- Table to Meta Analysis by R (codes from Moeller 2020 paper; results generated by Eleanor)
- Causal discovery by merging causal claims and statistics (by Zhijing & Sankalan)

# Run Code

- Clone repo 
`git clone https://github.com/flavioschneider/papers-ai.git`
- Go to models folder
`cd papers-ai/models/` 
- Install requirements `pip install -r requirements.txt` 
- Create experiment file in `config/exp` - see for example `annot_001.yaml`:
```yaml 
# @package _global_
type: script 

script:
  _target_: src.scripts.json_papers_annotate.JSONPapersAnnotate
  config:
    device: -1
    in_dir_json: ${work_dir}/../ui/public/json
    out_json: ${work_dir}/../ui/public/annot.json
    model_settings:
      accept_score: 0.45
    annotations:      
      - name: 'country'
        questions: [
          'In what country is the study?'
        ]
      - name: 'sample_size'
        questions: [
          'What is the number N?', 
          'What is the sample size?', 
          'How many people are in the study?'
        ]
```

Change `in_dir_json` to the folder with the input json papers, and `out_json` to the output json file to produce. The value `accept_score` is the confidence at which an annotation is accepted. You can provide a custom list of `annotations` with the questions used for extractive question answering (see the example). Then run the script on CPU `python run.py exp=annot_001` (or on GPU `python run.py exp=annot_001 script.config.device=0`) to generate the `annot.json` file. 
